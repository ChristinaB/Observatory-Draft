{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# A Notebook to TreatGeoSelf to easy access gridded climate time series data (Case study:  the Sauk-Suiattle Watershed )\n",
    "<img src= \"http://www.sauk-suiattle.com/images/Elliott.jpg\"\n",
    "style=\"float:left;width:150px;padding:20px\">   \n",
    "This data is compiled to digitally observe the Sauk-Suiattle Watershed, powered by HydroShare. <br />\n",
    "<br />\n",
    "Use this Jupyter Notebook to: <br /> \n",
    "Generate a list of available gridded data points in your area of interest, <br /> \n",
    "Download Livneh daily 1/16 degree gridded climate data, <br /> \n",
    "Download WRF daily 1/16 degree gridded climate data, <br /> \n",
    "Compare daily, monthly, and annual temperature and precipitation data. <br /> \n",
    "Visualize modeled streamflow results relative to the forcing data and observed streamflow. <br /> \n",
    "<br /> <br /> <br /> <img src=\"https://www.washington.edu/brand/files/2014/09/W-Logo_Purple_Hex.png\" style=\"float:right;width:120px;padding:20px\">  \n",
    "#### A Watershed Dynamics Model by the Watershed Dynamics Research Group in the Civil and Environmental Engineering Department at the University of Washington "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  HydroShare Setup and Preparation\n",
    "\n",
    "To run this notebook, we must import several libaries. These are listed in order of 1) Python standard libraries, 2) hs_utils library provides functions for interacting with HydroShare, including resource querying, dowloading and creation, and 3) the observatory_gridded_hydromet library that is downloaded with this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the python library fiona is not installed, please run the following lines in terminal, and choose 'y' when prompted. <br/>\n",
    "conda install -c conda-forge fiona <br>\n",
    "pip install fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: descartes in /opt/conda/envs/python2/lib/python2.7/site-packages\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python2/lib/python2.7/site-packages (from descartes)\r\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/conda/envs/python2/lib/python2.7/site-packages (from matplotlib->descartes)\r\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/envs/python2/lib/python2.7/site-packages (from matplotlib->descartes)\r\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/envs/python2/lib/python2.7/site-packages (from matplotlib->descartes)\r\n",
      "Requirement already satisfied: functools32 in /opt/conda/envs/python2/lib/python2.7/site-packages (from matplotlib->descartes)\r\n",
      "Requirement already satisfied: subprocess32 in /opt/conda/envs/python2/lib/python2.7/site-packages (from matplotlib->descartes)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python2/lib/python2.7/site-packages (from matplotlib->descartes)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python2/lib/python2.7/site-packages/cycler-0.10.0-py2.7.egg (from matplotlib->descartes)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /opt/conda/envs/python2/lib/python2.7/site-packages (from matplotlib->descartes)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install descartes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 2017-09-19 22:03:14 jp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from utilities import hydroshare\n",
    "import ogh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import fiona\n",
    "from shapely.geometry import shape, point, MultiPolygon, box\n",
    "\n",
    "from descartes import PolygonPatch\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a secure connection with HydroShare by instantiating the hydroshare class that is defined within hs_utils. In addition to connecting with HydroShare, this command also sets and prints environment variables for several parameters that will be useful for saving work back to HydroShare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the following system variables:\n",
      "   HS_USR_NAME = jphuong\n",
      "   HS_RES_ID = 0236ae196d204f1cba421787f38dec71\n",
      "   HS_RES_TYPE = genericresource\n",
      "   JUPYTER_HUB_IP = jupyter.cuahsi.org\n",
      "\n",
      "These can be accessed using the following command: \n",
      "   os.environ[key]\n",
      "\n",
      "   (e.g.)\n",
      "   os.environ[\"HS_USR_NAME\"]  => jphuong\n",
      "Successfully established a connection with HydroShare\n",
      "Data will be loaded from and save to:/home/jovyan/work/notebooks/data/0236ae196d204f1cba421787f38dec71/0236ae196d204f1cba421787f38dec71/data/contents\n"
     ]
    }
   ],
   "source": [
    "hs=hydroshare.hydroshare()\n",
    "homedir = ogh.mapContentFolder(str(os.environ[\"HS_RES_ID\"]))\n",
    "print('Data will be loaded from and save to:'+homedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious about where the data is being downloaded, click on the Jupyter Notebook dashboard icon to return to the File System view.  The homedir directory location printed above is where you can find the data and contents you will download to a HydroShare JupyterHub server.  At the end of this work session, you can migrate this data to the HydroShare iRods server as a Generic Resource. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get list of gridded climate points for the watershed\n",
    "\n",
    "This example uses a shapefile with the watershed boundary of the Sauk-Suiattle Basin, which is stored in HydroShare at the following url: https://www.hydroshare.org/resource/c532e0578e974201a0bc40a37ef2d284/. \n",
    "\n",
    "The data for our processing routines can be retrieved using the getResourceFromHydroShare function by passing in the global identifier from the url above.  In the next cell, we download this resource from HydroShare, and identify that the points in this resource are available for downloading gridded hydrometeorology data, based on the point shapefile at https://www.hydroshare.org/resource/ef2d82bf960144b4bfb1bae6242bcc7f/, which is for the extent of North America and includes the average elevation for each 1/16 degree grid cell.  The file must include columns with station numbers, latitude, longitude, and elevation. The header of these columns must be FID, LAT, LONG_, and ELEV or RASTERVALU, respectively. The station numbers will be used for the remainder of the code to uniquely reference data from each climate station, as well as to identify minimum, maximum, and average elevation of all of the climate stations.  The webserice is currently set to a URL for the smallest geographic overlapping extent - e.g. WRF for Columbia River Basin (to use a limit using data from a FTP service, treatgeoself() would need to be edited in observatory_gridded_hydrometeorology utility). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This resource already exists in your userspace.\n",
      "Would you like to overwrite this data [Y/n]? n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Found the following file(s) associated with this HydroShare resource.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wbdhuc12_17110006_WGS84.cpg<br>wbdhuc12_17110006_WGS84.sbx<br>wbdhuc12_17110006_WGS84.shx<br>wbdhuc12_17110006_WGS84.dbf<br>wbdhuc12_17110006_WGS84.sbn<br>wbdhuc12_17110006_WGS84.prj<br>wbdhuc12_17110006_WGS84.shp"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "These files are stored in a dictionary called <b>hs.content</b> for your convenience.  To access a file, simply issue the following command where MY_FILE is one of the files listed above: <pre>hs.content[\"MY_FILE\"] </pre> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This resource already exists in your userspace.\n",
      "Would you like to overwrite this data [Y/n]? n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Found the following file(s) associated with this HydroShare resource.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "NAmer_dem_list.cpg<br>NAmer_dem_list.sbn<br>NAmer_dem_list.sbx<br>NAmer_dem_list.dbf<br>NAmer_dem_list.shx<br>NAmer_dem_list.prj<br>NAmer_dem_list.shp"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "These files are stored in a dictionary called <b>hs.content</b> for your convenience.  To access a file, simply issue the following command where MY_FILE is one of the files listed above: <pre>hs.content[\"MY_FILE\"] </pre> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gridded points/files: 98\n",
      "(98, 4)\n",
      "    FID       LAT      LONG_    ELEV\n",
      "93   93  47.96875 -121.53125   987.0\n",
      "94   94  47.90625 -121.21875  1310.0\n",
      "95   95  47.90625 -121.28125  1061.0\n",
      "96   96  47.90625 -121.34375   934.0\n",
      "97   97  47.90625 -121.40625   866.0\n",
      "/home/jovyan/work/notebooks/Observatory/monkeysonatree.csv\n"
     ]
    }
   ],
   "source": [
    "#Your model extent\n",
    "hs.getResourceFromHydroShare('c532e0578e974201a0bc40a37ef2d284')\n",
    "shapefile = hs.content['wbdhuc12_17110006_WGS84.shp']\n",
    "\n",
    "# List of available data\n",
    "hs.getResourceFromHydroShare('ef2d82bf960144b4bfb1bae6242bcc7f')\n",
    "NAmer = hs.content['NAmer_dem_list.shp']\n",
    "\n",
    "# Generate list of stations to download\n",
    "mappingfile = ogh.treatgeoself(shapefile=shapefile, \n",
    "                               NAmer=NAmer,\n",
    "                               folder_path=os.getcwd(), \n",
    "                               outfilename='monkeysonatree.csv',\n",
    "                               buffer_distance=0.06)\n",
    "print(mappingfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ogh.renderWatershed(shapefile, outfilepath='watershed_topo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/notebooks/Observatory/ogh_meta.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metafile = [os.path.abspath(each) for each in os.listdir(os.getcwd()) if each in 'ogh_meta.json'][0]\n",
    "metafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(metafile, 'r') as j:\n",
    "    metadict = json.load(j)\n",
    "    j.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'date_range': {u'end': u'2011-12-31', u'start': u'1915-01-01'},\n",
       " u'meta': {u'PRECIP': {u'desc': u'Daily Total Precipitation mm',\n",
       "   u'dtypes': u'float64',\n",
       "   u'units': u'mm'},\n",
       "  u'TMAX': {u'desc': u'Daily Temperature Maximum',\n",
       "   u'dtypes': u'float64',\n",
       "   u'units': u'C'},\n",
       "  u'TMIN': {u'desc': u'Daily Temperature Minimum',\n",
       "   u'dtypes': u'float64',\n",
       "   u'units': u'C'},\n",
       "  u'WINDSPD': {u'desc': u'Wind Speed',\n",
       "   u'dtypes': u'float64',\n",
       "   u'units': u'mm'}},\n",
       " u'time_step': u'daily',\n",
       " u'variables': [u'PRECIP', u'TMAX', u'TMIN', u'WINDSPD']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadict['livneh2013_metdaily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1915-01-01', u'2011-12-31']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = metadict['livneh2013_metdaily']['date_range'].values()\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1950-01-01', u'2011-12-31']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = metadict['livneh2015_metdaily']['date_range'].values()\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'1950-01-01', u'2011-12-31')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = ogh.overlappingDates(d1, d2)\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1950-01-01', '1950-01-02', '1950-01-03', '1950-01-04',\n",
       "               '1950-01-05', '1950-01-06', '1950-01-07', '1950-01-08',\n",
       "               '1950-01-09', '1950-01-10',\n",
       "               ...\n",
       "               '2011-12-22', '2011-12-23', '2011-12-24', '2011-12-25',\n",
       "               '2011-12-26', '2011-12-27', '2011-12-28', '2011-12-29',\n",
       "               '2011-12-30', '2011-12-31'],\n",
       "              dtype='datetime64[ns]', length=22645, freq='D')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range(start=r1[0], end=r1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Download climate data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Daily Meteorologic Data (1915-2011) from Livneh et al. 2013 \n",
    "\n",
    "The functions used in this section apply to hydrometeorology data within the Continental United States with daily data 1915-2011. <br/>\n",
    "View data extent at  Livneh, B. (2017). Gridded climatology locations (1/16th degree): Continental United States extent, HydroShare, http://www.hydroshare.org/resource/14f0a6619c6b45cc90d1f8cabc4129af\n",
    "\n",
    "Please cite: <br/>\n",
    "Livneh B., E.A. Rosenberg, C. Lin, B. Nijssen, V. Mishra, K.M. Andreadis, E.P. Maurer, and D.P. Lettenmaier, 2013: A Long-Term Hydrologically Based Dataset of Land Surface Fluxes and States for the Conterminous United States: Update and Extensions, Journal of Climate, 26, 9384â€“9392.<br/>\n",
    "<br/>\n",
    "The getClimateData_DailyMET_livneh2013() function reads in the mapping file table, downloads, and unzips the data files for each of the longitude and latitude points. The folder containing the data is within the directory listed as homedir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.15625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.65625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.53125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.40625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.53125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.59375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.46875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.21875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.65625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.53125_-121.59375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.53125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.28125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.03125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.96875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.09375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.40625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.28125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.15625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.34375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.90625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.46875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.65625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.21875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.96875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.28125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.59375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.09375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.46875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.59375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.09375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.46875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.40625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.03125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.53125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.59375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.34375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.34375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.15625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.21875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.46875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.09375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.53125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.96875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.34375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.21875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.15625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.40625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-120.96875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.34375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.21875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.59375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.09375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.71875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.65625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.28125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.03125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-120.96875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.46875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.53125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.40625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.21875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.46875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-120.90625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.53125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.34375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.59375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.28125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.59375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.15625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.40625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.03125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.03125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-120.90625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.09375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.28125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.03125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.65625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.15625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.40625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.28125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.90625_-121.34375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.15625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.09375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.09375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.21875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.34375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.46875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.90625_-121.21875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.65625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.46875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.90625_-121.40625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.21875 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.90625_-121.28125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.40625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.34375 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.15625 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.28125 unzipped\n",
      "Meteorology_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.53125 unzipped\n"
     ]
    }
   ],
   "source": [
    "#Daily_MET_1915_2011 = ogh.getClimateData_DailyMET_livneh2013(homedir, mappingfile)\n",
    "Daily_MET_1915_2011 = ogh.getClimateData_DailyMET_livneh2013(homedir, mappingfile, subdir='livneh2013/Daily_MET_1915_2011', catalog_label='livneh2013_MET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FID       LAT      LONG_    ELEV  \\\n",
      "0    0  48.53125 -121.59375  1113.0   \n",
      "1    1  48.46875 -121.46875   646.0   \n",
      "2    2  48.46875 -121.53125   321.0   \n",
      "3    3  48.46875 -121.59375   164.0   \n",
      "4    4  48.46875 -121.65625   369.0   \n",
      "\n",
      "                                      livneh2013_MET  \n",
      "0  /home/jovyan/work/notebooks/data/0236ae196d204...  \n",
      "1  /home/jovyan/work/notebooks/data/0236ae196d204...  \n",
      "2  /home/jovyan/work/notebooks/data/0236ae196d204...  \n",
      "3  /home/jovyan/work/notebooks/data/0236ae196d204...  \n",
      "4  /home/jovyan/work/notebooks/data/0236ae196d204...  \n",
      "('Number of gridded data files:', 98)\n",
      "('Minimum elevation: ', 164.0, 'm')\n",
      "('Mean elevation: ', 1162, 'm')\n",
      "('Maximum elevation: ', 2216.0, 'm')\n"
     ]
    }
   ],
   "source": [
    "climate_df, nstations = ogh.mappingfileToDF(mappingfile, colvar='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1915-01-01', u'2011-12-31']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = metadict['livneh2013_metdaily']['date_range'].values()\n",
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Meteorologic climate data (1950-2013) from Livneh et al. 2015\n",
    "\n",
    "The functions used in this section apply to hydrometeorology data is within the North America area with daily data 1950-2013. View the data extent from this HydroShare resource: Livneh, B. (2017). Gridded climatology locations (1/16th degree): North American extent, HydroShare,  http://www.hydroshare.org/resource/ef2d82bf960144b4bfb1bae6242bcc7f\n",
    "\n",
    "Please cite: <br/>\n",
    "Livneh B., T.J. Bohn, D.S. Pierce, F. Munoz-Ariola, B. Nijssen, R. Vose, D. Cayan, and L.D. Brekke, 2015: A spatially comprehensive, hydrometeorological data set for Mexico, the U.S., and southern Canada 1950-2013, Nature Scientific Data, 5:150042, doi:10.1038/sdata.2015.42.<br/>\n",
    "<br/>\n",
    "The getClimateData_DailyMET_livneh2015() function reads in the mapping file table, downloads, and unzips the data files for each of the longitude and latitude points. The folder containing the data is within the directory listed as homedir. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.40625_-121.40625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.46875_-121.65625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.34375_-121.40625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.28125_-120.96875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.34375_-121.15625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.34375_-121.53125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.34375_-121.28125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.40625_-121.15625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.53125_-121.59375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.40625_-121.28125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.40625_-121.65625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.40625_-121.53125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.34375_-121.03125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.28125_-121.21875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.46875_-121.53125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.28125_-121.59375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-120.90625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.28125_-121.09375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.28125_-121.46875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.28125_-121.34375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.34375_-121.46875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.34375_-121.21875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.40625_-121.21875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.40625_-121.09375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.34375_-121.34375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.34375_-121.59375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.40625_-121.46875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.28125_-121.03125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.46875_-121.46875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.40625_-121.34375 unzipped\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "[Errno 110] Connection timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31merror\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f887d80d968e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDaily_MET_1950_2013\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mogh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetClimateData_DailyMET_livneh2015\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappingfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jovyan/work/notebooks/Observatory/ogh.pyc\u001b[0m in \u001b[0;36mgetClimateData_DailyMET_livneh2015\u001b[0;34m(homedir, mappingfile, subdir, catalog_label)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;31m# Download the files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m     \u001b[0mftp_download_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;31m# update the mappingfile with the file catalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/work/notebooks/Observatory/ogh.pyc\u001b[0m in \u001b[0;36mftp_download_p\u001b[0;34m(listofinterest, nworkers)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftp_download_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistofinterest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    249\u001b[0m         '''\n\u001b[1;32m    250\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: [Errno 110] Connection timed out"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-121.46875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-121.59375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-121.71875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.09375_-120.96875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.09375_-121.09375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.03125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.15625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-121.21875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.28125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.40625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.65625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-121.09375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-120.96875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.53125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-121.53125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.09375_-121.15625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-121.65625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.09375_-120.90625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.09375_-121.03125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.09375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.34375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.59375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.46875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.21875_-121.21875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-121.15625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-121.28125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-120.90625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.15625_-121.03125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.03125_-121.15625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.03125_-121.40625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.03125_-121.28125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.96875_-121.09375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.96875_-121.21875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.96875_-121.34375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.96875_-121.46875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.90625_-121.21875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.90625_-121.34375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.03125_-121.34375 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.03125_-121.21875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_48.03125_-121.46875 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.96875_-121.28125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.96875_-121.15625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.96875_-121.40625 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.96875_-121.53125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.90625_-121.28125 unzipped\n",
      "Meteorology_Livneh_NAmerExt_15Oct2014_47.90625_-121.40625 unzipped\n"
     ]
    }
   ],
   "source": [
    "Daily_MET_1950_2013 = ogh.getClimateData_DailyMET_livneh2015(homedir, mappingfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_in_all_files in module ogh:\n",
      "\n",
      "read_in_all_files(map_df, dataset, file_start_date, file_end_date, subset_start_date, subset_end_date, file_colnames=['precip_mm', 'tmax_c', 'tmin_c', 'wind_m_s'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ogh.read_in_all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FID       LAT      LONG_    ELEV  \\\n",
      "0    0  48.53125 -121.59375  1113.0   \n",
      "1    1  48.46875 -121.46875   646.0   \n",
      "2    2  48.46875 -121.53125   321.0   \n",
      "3    3  48.46875 -121.59375   164.0   \n",
      "4    4  48.46875 -121.65625   369.0   \n",
      "\n",
      "                                      livneh2013_MET  \n",
      "0  /home/jovyan/work/notebooks/data/0236ae196d204...  \n",
      "1  /home/jovyan/work/notebooks/data/0236ae196d204...  \n",
      "2  /home/jovyan/work/notebooks/data/0236ae196d204...  \n",
      "3  /home/jovyan/work/notebooks/data/0236ae196d204...  \n",
      "4  /home/jovyan/work/notebooks/data/0236ae196d204...  \n",
      "('Number of gridded data files:', 98)\n",
      "('Minimum elevation: ', 164.0, 'm')\n",
      "('Mean elevation: ', 1162, 'm')\n",
      "('Maximum elevation: ', 2216.0, 'm')\n",
      "               PRECIP   TMAX       TMIN  WINDSPD\n",
      "1950-01-01   3.600000  -4.37  -9.710000   3.0133\n",
      "1950-01-02   2.850000  -8.12 -15.660000   1.4688\n",
      "1950-01-03   3.100000 -12.56 -21.620001   1.3527\n",
      "1950-01-04   4.725000  -8.89 -16.850000   1.5555\n",
      "1950-01-05   6.475000  -6.06 -16.610001   2.8146\n",
      "1950-01-06  19.799999  -4.51  -7.050000   3.2362\n",
      "1950-01-07   8.425000  -3.34  -6.580000   2.0943\n",
      "1950-01-08   3.700000  -3.08  -6.910000   0.7056\n",
      "1950-01-09   7.475000  -2.71  -7.030000   2.3275\n",
      "1950-01-10  14.625000  -1.53  -6.980000   6.3469\n"
     ]
    }
   ],
   "source": [
    "climate_df, nstations = ogh.mappingfileToDF(mappingfile, colvar='all')\n",
    "\n",
    "all_daily = ogh.read_in_all_files(map_df=climate_df,\n",
    "                                  dataset='livneh2013_MET',\n",
    "                                  file_start_date=d1[0],\n",
    "                                  file_end_date=d1[1], \n",
    "                                  subset_start_date=r1[0],\n",
    "                                  subset_end_date=r1[1],\n",
    "                                  file_colnames=metadict['livneh2013_metdaily']['variables'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.panel.Panel'>\n",
       "Dimensions: 98 (items) x 22645 (major_axis) x 4 (minor_axis)\n",
       "Items axis: (0, 48.53125, -121.59375) to (97, 47.90625, -121.40625)\n",
       "Major_axis axis: 1950-01-01 00:00:00 to 2011-12-31 00:00:00\n",
       "Minor_axis axis: PRECIP to WINDSPD"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.Panel.from_dict(all_daily)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridclimname='something'\n",
    "dicto=dict()\n",
    "\n",
    "for eachvar in metadict['livneh2013_metdaily']['variables']:\n",
    "    dicto['_'.join([eachvar,gridclimname])] = temp.xs(key=eachvar, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'WINDSPD_something',\n",
       " u'PRECIP_something',\n",
       " u'TMAX_something',\n",
       " u'TMIN_something']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicto.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get VIC outputs from Livneh et al., 2013 and Livneh et al., 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.53125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.15625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.15625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.65625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.03125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.28125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.53125_-121.59375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.28125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.53125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.21875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.34375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.21875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.34375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.59375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.34375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.40625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.96875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.59375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.53125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.46875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.21875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.59375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.15625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.28125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.40625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.65625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.09375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.09375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.09375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.96875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.59375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.03125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.09375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.40625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.65625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.65625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.53125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.28125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.40625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.46875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.21875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-120.96875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.46875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.03125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.21875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.15625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.03125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.46875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.09375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.71875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.34375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.46875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.34375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.59375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.59375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-120.96875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.21875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.15625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.03125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.34375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.09375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.28125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.59375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.15625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.46875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-120.90625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.15625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.90625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.46875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-120.90625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.21875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.03125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.28125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.09375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.65625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.40625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.21875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.96875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.09375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.28125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.90625_-121.21875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.34375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.53125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.46875 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.53125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.40625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.40625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.09375_-121.65625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.15625_-121.53125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.90625_-121.34375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.15625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.34375 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.28125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.53125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.90625_-121.28125 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.96875_-121.40625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_47.90625_-121.40625 unzipped\n",
      "VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_48.03125_-121.46875 unzipped\n"
     ]
    }
   ],
   "source": [
    "Daily_VIC_1915_2011 = ogh.getClimateData_DailyVIC_livneh2013(homedir, mappingfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-121.03125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.40625_-121.40625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.46875_-121.53125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.34375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-121.40625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-121.28125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.46875_-121.65625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-121.15625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.40625_-121.15625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-121.53125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.09375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.21875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.40625_-121.65625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.46875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-120.96875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.40625_-121.53125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.53125_-121.59375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.40625_-121.28125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.59375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.21875_-120.90625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-121.09375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.40625_-121.46875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-121.21875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.40625_-121.09375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.46875_-121.59375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-121.34375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.40625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.40625_-121.21875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-121.46875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.28125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.15625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-121.59375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.34375_-120.96875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.40625_-121.34375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.40625_-121.59375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.46875_-121.46875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.21875_-120.96875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.03125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.53125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.28125_-121.65625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.21875_-121.03125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.21875_-121.28125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.21875_-121.53125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.21875_-121.40625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.21875_-121.15625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.21875_-121.65625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.15625_-120.96875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.15625_-121.09375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.15625_-121.34375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.15625_-121.46875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.15625_-121.21875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.15625_-121.59375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.09375_-121.09375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.09375_-121.46875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.15625_-121.71875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.09375_-120.96875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.09375_-121.34375 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.09375_-121.21875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.09375_-121.28125 unzipped\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "[Errno 110] Connection timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31merror\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-65cb11769473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDaily_VIC_1950_2013\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mogh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetClimateData_DailyVIC_livneh2015\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappingfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jovyan/work/notebooks/Observatory/ogh.pyc\u001b[0m in \u001b[0;36mgetClimateData_DailyVIC_livneh2015\u001b[0;34m(homedir, mappingfile, subdir, catalog_label)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;31m# Download the files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m     \u001b[0mftp_download_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# update the mappingfile with the file catalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/work/notebooks/Observatory/ogh.pyc\u001b[0m in \u001b[0;36mftp_download_p\u001b[0;34m(listofinterest, nworkers)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftp_download_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistofinterest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    249\u001b[0m         '''\n\u001b[1;32m    250\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: [Errno 110] Connection timed out"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.03125_-121.28125 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.03125_-121.40625 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.03125_-121.46875 unzipped\n",
      "Fluxes_Livneh_NAmerExt_15Oct2014_48.03125_-121.34375 unzipped\n"
     ]
    }
   ],
   "source": [
    "Daily_VIC_1950_2013 = ogh.getClimateData_DailyVIC_livneh2015(homedir, mappingfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Get the raw and bias corrected Daily Weather Research and Forecasting (WRF 1950-2010 Pacific Northwest) from Salathe et al., 2014\n",
    "<br/>\n",
    "Please cite 2014 data using: <br/>\n",
    "SalathÃ©, EP, AF Hamlet, CF Mass, M Stumbaugh, S-Y Lee, R Steed: 2017. Estimates of 21st Century Flood Risk in the Pacific Northwest Based on Regional Scale Climate Model Simulations.  J. Hydrometeorology. DOI: 10.1175/JHM-D-13-0137.1\n",
    "\n",
    "This data is also available on HydroShare and can be downloaded using the following line of code (copy into code block):\n",
    "hs.getResourceFromHydroShare('0db969e4cfb54cb18b4e1a2014a26c82')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Daily_WRFraw_1950_2010 = ogh.getClimateData_DailyMET_rawWRF(homedir, mappingfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Daily_WRFbc_1950_2010 = ogh.getClimateData_DailyMET_bcWRF(homedir, mappingfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('This is the list of folders in your user space.')\n",
    "test = [each for each in os.listdir(homedir) if os.path.isdir(each) and not each.startswith(\".\")]\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ogh.renderPointsInShape(shapefile=shapefile, NAmer=NAmer, mappingfile=mappingfile, outfilepath='oghcat_Livneh_Salathe.png')\n",
    "tmp, nstations = ogh.mappingfileToDF(mappingfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create list of dataframe\n",
    "all_daily = ogh.read_in_all_files(map_df=tmp,\n",
    "                                  dataset='livneh2013_MET',\n",
    "                                  file_start_date=datetime(1915,1,1), \n",
    "                                  file_end_date=datetime(2011,12,31),\n",
    "                                  subset_start_date=datetime(1950,1,1),\n",
    "                                  subset_end_date=datetime(2010,12,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(all_daily.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# needs to be reconstructed\n",
    "\n",
    "def generateVarTables (listOfDates, dictOfTables, n_stations):\n",
    "    # NOTE: each table from dictOfTable must contain:\n",
    "    # tmin_c, tmax_c, precip_mm, wind_m_s\n",
    "    \n",
    "    len_listOfDates=len(listOfDates) # number of dates\n",
    "    \n",
    "    # Create arrays of for each variable of interest (Tmin, Tmax, Precip).\n",
    "    # Rows are dates of analysis and columns are the station number\n",
    "    temp_min_np=np.empty([len_listOfDates,n_stations])\n",
    "    temp_max_np=np.empty([len_listOfDates,n_stations])\n",
    "    precip_np=np.empty([len_listOfDates,n_stations])\n",
    "    wind_np=np.empty([len_listOfDates,n_stations])\n",
    "    \n",
    "    # fill in each array with values from each station\n",
    "    for i in sorted(dictOfTables.keys()):\n",
    "        temp_min_np[:,i]=dictOfTables[i].tmin_c.values.astype(float)\n",
    "        temp_max_np[:,i]=dictOfTables[i].tmax_c.values.astype(float)\n",
    "        precip_np[:,i]=dictOfTables[i].precip_mm.values.astype(float)\n",
    "        wind_np[:,i]=dictOfTables[i].wind_m_s.values.astype(float)\n",
    "        \n",
    "    # generate each variable dataframe with rows as dates and columns as stations\n",
    "    temp_min_df=pd.DataFrame(temp_min_np, columns=sorted(dictOfTables.keys()), index=listOfDates)    \n",
    "    temp_max_df=pd.DataFrame(temp_max_np, columns=sorted(dictOfTables.keys()), index=listOfDates)    \n",
    "    precip_df=pd.DataFrame(precip_np, columns=sorted(dictOfTables.keys()), index=listOfDates)    \n",
    "    wind_df=pd.DataFrame(wind_np, columns=sorted(dictOfTables.keys()), index=listOfDates)\n",
    "    \n",
    "    # Create average temperature data frame as the average of Tmin and Tmax\n",
    "    temp_avg_df=pd.DataFrame((temp_min_np+temp_max_np)/2, columns=sorted(dictOfTables.keys()), index=listOfDates)\n",
    "    \n",
    "    # generate each variable dataframe with rows as dates and columns as stations\n",
    "    \n",
    "    \n",
    "    return(temp_min_df, temp_max_df, precip_df, wind_df, temp_avg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Compare Hydrometeorology \n",
    "\n",
    "This section performs computations and generates plots of the Livneh 2013, Livneh 2016, and WRF 2014 temperature and precipitation data in order to compare them with each other and observations. The generated plots are automatically downloaded and saved as .png files in the \"plots\" folder of the user's home directory and inline in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT: Location Name and watershed drainage area (m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loc_name='Sauk Watershed'\n",
    "streamflow_watershed_drainage_area=1849242318 # square meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT: gridded meteorology from Jupyter Hub folders\n",
    "Data frames for each set of data are stored in a dictionary. The inputs to gridclim_dict() include the folder location and name of the hydrometeorology data, the file start and end, the analysis start and end, and the elevation band to be included in the analsyis (max and min elevation). <br/>  \n",
    "\n",
    "#### Create a dictionary of climate variables for the long-term mean (ltm) using the default elevation option of calculating a high, mid, and low elevation average.  The dictionary here is initialized with the Livneh et al., 2013 dataset with a dictionary output 'ltm_3bands', which is used as an input to the second time we run gridclim_dict(), to add the Salathe et al., 2014 data to the same dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ltm_3bands = ogh.gridclim_dict(gridclim_folder='livneh2013_MET',\n",
    "                               gridclimname='liv2013_met_daily',\n",
    "                               loc_name=loc_name,\n",
    "                               mappingfile=mappingfile, \n",
    "                               file_start_date=datetime(1915,1,1), \n",
    "                               file_end_date=datetime(2011,12,31),\n",
    "                               subset_start_date=datetime(1950,1,1),\n",
    "                               subset_end_date=datetime(2010,12,31))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparison to WRF data from Salathe et al., 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ltm_3bands = ogh.gridclim_dict(gridclim_folder=Daily_WRFraw_1950_2010,\n",
    "                               gridclimname='wrf2014_met_daily',\n",
    "                               loc_name=loc_name,\n",
    "                               mappingfile=mappingfile,\n",
    "                               file_start_date=datetime(1950,1,1), \n",
    "                               file_end_date=datetime(2010,12,31),\n",
    "                               subset_start_date=datetime(1950,1,1),\n",
    "                               subset_end_date=datetime(2010,12,31),  \n",
    "                               df_dict=ltm_3bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Download gridded hydrology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get VIC Hydrology Model data (1950-2013) from Livneh et al. 2016\n",
    "\n",
    "The functions used in this section apply to hydrometeorology data is within the North America area with daily data 1950-2013. View the data extent from this HydroShare resource: Livneh, B. (2017). Gridded climatology locations (1/16th degree): North American extent, HydroShare,  http://www.hydroshare.org/resource/ef2d82bf960144b4bfb1bae6242bcc7f\n",
    "\n",
    "Please cite: <br/>\n",
    "Livneh B., T.J. Bohn, D.S. Pierce, F. Munoz-Ariola, B. Nijssen, R. Vose, D. Cayan, and L.D. Brekke, 2015: A spatially comprehensive, hydrometeorological data set for Mexico, the U.S., and southern Canada 1950-2013, Nature Scientific Data, 5:150042, doi:10.1038/sdata.2015.42.<br/>\n",
    "<br/>\n",
    "The getClimateData_DailyVIC_USA_livneh2013() function reads in the mapping file table, downloads, and unzips the data files for each of the longitude and latitude points. Values in Canada use a different folder structure and can be downloaded with the function getClimateData_DailyVIC_CAN_livneh2013() The folder containing the data is within the directory listed as homedir. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Daily_VIC_1950_2013 = ogh.getClimateData_DailyVIC_livneh2015(homedir, mappingfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(ltm_3bands.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Compare gridded model to point observations\n",
    "\n",
    "### Read in  SNOTEL data - assess available data \n",
    "If you want to plot observed snotel point precipitation or temperature with the gridded climate data, set to 'Y' \n",
    "Give name of Snotel file and name to be used in figure legends. \n",
    "File format: Daily SNOTEL Data Report - Historic - By individual SNOTEL site, standard sensors (https://www.wcc.nrcs.usda.gov/snow/snotel-data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sauk\n",
    "SNOTEL_file = os.path.join(homedir,'ThunderBasinSNOTEL.txt')\n",
    "SNOTEL_station_name='Thunder Creek'\n",
    "SNOTEL_file_use_colsnames = ['Date','Air Temperature Maximum (degF)', 'Air Temperature Minimum (degF)','Air Temperature Average (degF)','Precipitation Increment (in)']\n",
    "SNOTEL_station_elev=int(4320/3.281) # meters\n",
    "\n",
    "SNOTEL_obs_daily = ogh.read_daily_snotel(file_name=SNOTEL_file, \n",
    "                                         usecols=SNOTEL_file_use_colsnames, \n",
    "                                         delimiter=',', \n",
    "                                         header=58)\n",
    "\n",
    "# generate the start and stop date\n",
    "SNOTEL_obs_start_date=SNOTEL_obs_daily.index[0]\n",
    "SNOTEL_obs_end_date=SNOTEL_obs_daily.index[-1]\n",
    "\n",
    "# peek\n",
    "print(SNOTEL_obs_daily.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in  COOP station data - assess available data\n",
    "https://www.ncdc.noaa.gov/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "COOP_file=os.path.join(homedir, 'USC00455678.csv') # Sauk\n",
    "COOP_station_name='Mt Vernon'\n",
    "COOP_file_use_colsnames = ['DATE','PRCP','TMAX', 'TMIN','TOBS']\n",
    "COOP_station_elev=int(4.3) # meters\n",
    "\n",
    "COOP_obs_daily = ogh.read_daily_coop(file_name=COOP_file,\n",
    "                                     usecols=COOP_file_use_colsnames,\n",
    "                                     delimiter=',',\n",
    "                                     header=0)\n",
    "\n",
    "# generate the start and stop date\n",
    "COOP_obs_start_date=COOP_obs_daily.index[0]\n",
    "COOP_obs_end_date=COOP_obs_daily.index[-1]\n",
    "\n",
    "# peek\n",
    "print(COOP_obs_daily.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up VIC dictionary (as an example)  to compare to available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ltm_3bands_vic = ogh.gridhydro_dict(gridclim_folder=Daily_VIC_1950_2013,\n",
    "                               gridclimname='liv2013_vic_daily',\n",
    "                               loc_name=loc_name,\n",
    "                               mappingfile=mappingfile,\n",
    "                               file_start_date=datetime(1915,1,1), \n",
    "                               file_end_date=datetime(2011,12,31),\n",
    "                               subset_start_date=datetime(1950,1,1),  #matched COOP and Snotel\n",
    "                               subset_end_date=datetime(2010,12,31)\n",
    "                               model='vic2013')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save the results back into HydroShare\n",
    "<a name=\"creation\"></a>\n",
    "\n",
    "Using the `hs_utils` library, the results of the Geoprocessing steps above can be saved back into HydroShare.  First, define all of the required metadata for resource creation, i.e. *title*, *abstract*, *keywords*, *content files*.  In addition, we must define the type of resource that will be created, in this case *genericresource*.  \n",
    "\n",
    "***Note:*** Make sure you save the notebook at this point, so that all notebook changes will be saved into the new HydroShare resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#execute this cell to list the content of the directory\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of files to save to HydroShare. Verify location and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ThisNotebook='Observatory_Sauk_TreatGeoSelf.ipynb' #check name for consistency\n",
    "climate2013_tar = 'livneh2013.tar.gz'\n",
    "climate2015_tar = 'livneh2015.tar.gz'\n",
    "wrf_tar = 'Salathe2014.tar.gz'\n",
    "!tar -zcf {climate2013_tar} livneh2013\n",
    "!tar -zcf {climate2015_tar} livneh2015\n",
    "!tar -zcf {wrf_tar} Salathe2014\n",
    "\n",
    "files=[ThisNotebook,\n",
    "       'monkeysonatree.csv',\n",
    "       'avg_monthly_precip Sauk Watershed.png',\n",
    "       'avg_monthly_temp Sauk Watershed.png',\n",
    "       'observatory_gridded_hydromet.py',\n",
    "        climate2013_tar,\n",
    "        climate2015_tar,\n",
    "        wrf_tar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each file downloaded onto the server folder, move to a new HydroShare Generic Resource\n",
    "title = 'Results from testing out the TreatGeoSelf utility'\n",
    "abstract = 'This the output from the TreatGeoSelf utility integration notebook.\n",
    "keywords = ['Sauk', 'climate', 'Landlab','hydromet','watershed'] \n",
    "rtype = 'genericresource'  \n",
    "\n",
    "# create the new resource\n",
    "resource_id = hs.createHydroShareResource(abstract, \n",
    "                                          title,\n",
    "                                          keywords=keywords, \n",
    "                                          resource_type=rtype, \n",
    "                                          content_files=files, \n",
    "                                          public=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
